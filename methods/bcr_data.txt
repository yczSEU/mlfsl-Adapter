from torch import nn
from methods.template import MLLTemplate
import torch
import torch.nn.functional as F

class BCR(MLLTemplate):
    def __init__(self, model_func, n_way, n_shot, n_query, eta=0.01, gamma=0.01,
                 hidden_dim=100, device='cuda:0', verbose=False):
        super(BCR, self).__init__(model_func=model_func, n_way=n_way, n_shot=n_shot, n_query=n_query,
                                  device=device, verbose=verbose)
        self.eta = eta
        self.gamma = gamma
        
        self.encoder_x = nn.Linear(self.feat_dim, hidden_dim)
        self.input_norm = nn.LayerNorm(self.feat_dim)
        self.encoder_y = nn.Linear(self.n_way, hidden_dim)
        self.encoder_z = nn.Linear(hidden_dim * 2, hidden_dim)

        backbone_params = []
        scale_params = []
        head_params = []
        
        for name, param in self.named_parameters():
            if not param.requires_grad: continue
            if 'scale' in name:
                scale_params.append(param)
            elif 'feature_extractor' in name:
                backbone_params.append(param)
            else:
                head_params.append(param)

        self.optimizer = torch.optim.Adam([
            {'params': backbone_params, 'lr': 1e-5}, 
            {'params': scale_params,    'lr': 5e-3, 'weight_decay': 1e-3}, 
            {'params': head_params,     'lr': 1e-3}  
        ])
        
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=30, eta_min=1e-6
        )
        self.to(self.device)

    EPS = 1e-6

    def clean_multi_labels(self, x_support, y_support, y_query=None):
        """
        修复版清洗函数：移除 set() 去重逻辑，强制保留 n_way 个列
        """
        n_shot = x_support.shape[0] // self.n_way
        target_indices = []
        
        # 逐个 Way 扫描
        for i in range(self.n_way):
            start_idx = i * n_shot
            end_idx = (i + 1) * n_shot
            
            # 边界保护
            if start_idx >= y_support.shape[0]: 
                # 万一算错了，随便补一个 0，保证不崩
                target_indices.append(0)
                continue
            
            chunk = y_support[start_idx : end_idx]
            if chunk.shape[0] > 0:
                # 找出这一组 Support 样本中出现最多的标签索引
                class_idx = chunk.sum(dim=0).argmax().item()
                target_indices.append(class_idx)
            else:
                target_indices.append(0)
        
        # === 核心修改：不要使用 set() 去重！===
        # 即使有重复类，我们也要保留列表长度为 n_way，对应 10 个分类头
        # target_indices = sorted(list(set(target_indices))) <--- 删掉这行
        
        # 双重保险：强制截断或补齐到 n_way
        if len(target_indices) > self.n_way:
            target_indices = target_indices[:self.n_way]
        elif len(target_indices) < self.n_way:
            # 这种情况理论上不该发生，除非 n_shot=0
            target_indices.extend([0] * (self.n_way - len(target_indices)))
            
        # 执行切片
        y_support_clean = y_support[:, target_indices]
        y_query_clean = y_query[:, target_indices] if y_query is not None else None
        
        return y_support_clean, y_query_clean

    def set_forward(self, x_support, y_support, x_query):
        # 推理时也要清洗
        if y_support.shape[1] > self.n_way:
            y_support, _ = self.clean_multi_labels(x_support, y_support)
            
        y_support = y_support.float()
        z_support = self.feature_extractor(x_support)
        z_query = self.feature_extractor(x_query)
        
        z_support = self.input_norm(z_support)
        z_query = self.input_norm(z_query)
        
        z_support = F.normalize(z_support, p=2, dim=-1)
        z_query = F.normalize(z_query, p=2, dim=-1)
        
        weight = y_support / torch.sum(y_support, dim=0, keepdim=True)
        proto = torch.transpose(weight, 0, 1) @ z_support
        
        sim = torch.relu(self.cosine_similarity(z_support, proto))
        attention = y_support * sim + 1e-7
        attention = attention / torch.sum(attention, dim=0, keepdim=True)
        proto = torch.transpose(attention, 0, 1) @ z_support
        
        # FP32 计算距离
        z_query_f = z_query.float()
        proto_f = proto.float()
        
        scores = -self.euclidean_dist(z_query_f, proto_f) / 1.0
        scores = torch.sigmoid(scores) * 2
        scores = torch.nan_to_num(scores, nan=0.0)
        scores = torch.clamp(scores, min=self.EPS, max=1.0-self.EPS)
        
        return scores

    def set_forward_loss(self, x_support, y_support, x_query, y_query):
        # 训练时清洗
        if y_support.shape[1] > self.n_way:
            y_support, y_query = self.clean_multi_labels(x_support, y_support, y_query)
            
        y_support = y_support.float()
        z_support = self.feature_extractor(x_support)
        z_query = self.feature_extractor(x_query)
        
        z_support = self.input_norm(z_support)
        z_query = self.input_norm(z_query)
        
        z_support = F.normalize(z_support, p=2, dim=-1)
        z_query = F.normalize(z_query, p=2, dim=-1)
        
        weight = y_support / torch.sum(y_support, dim=0, keepdim=True)
        proto = torch.transpose(weight, 0, 1) @ z_support
        sim = torch.relu(self.cosine_similarity(z_support, proto))
        attention = y_support * sim + 1e-7
        attention = attention / torch.sum(attention, dim=0, keepdim=True)
        proto = torch.transpose(attention, 0, 1) @ z_support
        
        # FP32 主 Loss
        z_query_f = z_query.float()
        proto_f = proto.float()
        
        scores = -self.euclidean_dist(z_query_f, proto_f) / 1.0
        scores = torch.sigmoid(scores) * 2
        scores = torch.nan_to_num(scores, nan=0.0)
        scores = torch.clamp(scores, min=self.EPS, max=1.0-self.EPS)
        
        loss_cls = nn.BCELoss()(scores, y_query)
        
        # ------------------------ LE loss ------------------------
        z_support_detached = z_support.detach()
        z_query_detached = z_query.detach()
        
        x = torch.cat([z_support_detached, z_query_detached], dim=0)
        y = torch.cat([y_support, y_query], dim=0)
        
        dx = self.encoder_x(x)
        # 这里的 y 已经是清洗过、维度正确的了
        dy = self.encoder_y(y) 
        dz = self.encoder_z(torch.concat([dx, dy], dim=1))
        
        S = self.cosine_similarity(dz, dz)
        yy = S @ y
        loss_cl = nn.BCEWithLogitsLoss()(yy, y)
        
        weight = y / torch.sum(y, dim=0, keepdim=True)
        proto = torch.transpose(weight, 0, 1) @ x
        sim = torch.relu(self.cosine_similarity(x, proto))
        attention = y * sim + 1e-7
        attention = attention / torch.sum(attention, dim=0, keepdim=True)
        proto = torch.transpose(attention, 0, 1) @ x
        
        x_f = x.float()
        proto_2_f = proto.float()
        
        sscores = -self.euclidean_dist(x_f, proto_2_f) / 64.0
        loss_li = nn.CrossEntropyLoss()(sscores, torch.softmax(yy, dim=1))
        
        return loss_cls + loss_cl * self.eta + loss_li * self.gamma