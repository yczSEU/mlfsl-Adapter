import optuna
import torch
import os
import argparse
import numpy as np
import sys
import csv

from utils.utils import set_seed, base_path, get_dataloader
from methods.bcr import BCR
from utils.backbone import model_dict

# ----------------------------------------------------------------------
# åŸºç¡€é…ç½® (ä¼šè¢«å‘½ä»¤è¡Œå‚æ•°è¦†ç›–)
# ----------------------------------------------------------------------
DEFAULT_CONFIG = {
    'model_name': 'ViT-B-Adapter',
    'n_way': 10,
    'max_epoch': 15,  # æœç´¢æ—¶è·‘ 15 è½®è¶³å¤Ÿçœ‹è¶‹åŠ¿
    'hidden_dim': 512,
    'device': 'cuda:0',
    # 'seed': 0, # [ä¿®æ”¹] å»æ‰é»˜è®¤ seedï¼Œè®©å¹¶è¡Œè¿›ç¨‹éšæœº
    'num_workers': 4
}

def objective(trial, args):
    # =================================================================
    # 1. å®šä¹‰ç²¾ç®€åçš„æœç´¢ç©ºé—´ (Smart Search Space)
    # =================================================================
    
    # [A] å…³é”®å˜é‡ (é‡ç‚¹æœ)
    # Scale: æ ¹æ®åˆ†æï¼Œ0.12~0.16 æœ€å¥½ï¼Œä½†ä¹Ÿä¿ç•™ 0.02 çš„å¯èƒ½æ€§
    suggest_min_scale = trial.suggest_float("min_scale", 0.01, 0.10, step=0.01)
    
    # Alpha: 0.5 å’Œ 2.0 éƒ½æœ‰å¯èƒ½
    suggest_alpha = trial.suggest_categorical("alpha_balance", [0.5, 1.0, 1.5, 2.0])
    
    # LR: é›†ä¸­åœ¨ 5e-4 ~ 1.2e-3
    suggest_lr_adapter = trial.suggest_float("lr_adapter", 5e-4, 1.5e-3, log=True)
    
    # (å¯é€‰) Head LR: å¦‚æœä½ è¿˜æƒ³ç¨å¾®åŠ¨ä¸€ä¸‹ï¼Œå¯ä»¥æœï¼Œæˆ–è€…ç›´æ¥è·Ÿ Adapter ä¿æŒä¸€è‡´
    # è¿™é‡Œå»ºè®®è¿˜æ˜¯ç»™ä¸€ç‚¹è‡ªç”±åº¦ï¼Œä½†èŒƒå›´å¾ˆå°
    suggest_lr_head = trial.suggest_float("lr_head", 5e-4, 1.5e-3, log=True)

    # [B] å›ºå®šå˜é‡ (ç›´æ¥å†™æ­»ï¼ŒèŠ‚çœç®—åŠ›)
    fixed_beta = 4.5         # æ ¹æ® Top 20 åˆ†æå¾—å‡º
    fixed_ortho = 0.5        # ä¸æ•æ„Ÿï¼Œå–ä¸­é—´å€¼
    fixed_router_w = 1.0     # é»˜è®¤å€¼
    fixed_aux = 0.8          # æ ¹æ® Top 20 åˆ†æå¾—å‡º
    
    if args.n_shot == 1:
        fixed_fid_thresh = 0.96
    else:
        fixed_fid_thresh = 0.89 # æ ¹æ® Top 20 åˆ†æå¾—å‡º

    # =================================================================
    # 2. åˆå§‹åŒ–ç¯å¢ƒå’Œæ•°æ®
    # =================================================================
    device = DEFAULT_CONFIG['device']
    # set_seed(0) # [ä¿®æ”¹] ä¸è¦åœ¨ objective é‡Œè®¾å›ºå®šçš„ seedï¼Œå¦åˆ™å¹¶è¡Œä¼šæ’è½¦
    
    # å»ºç«‹æ¨¡å‹
    model = BCR(model_func=model_dict[DEFAULT_CONFIG['model_name']],
                n_way=DEFAULT_CONFIG['n_way'],
                n_shot=args.n_shot,
                n_query=DEFAULT_CONFIG['n_way'] // 2,
                hidden_dim=DEFAULT_CONFIG['hidden_dim'],
                eta=fixed_aux,     # [å›ºå®š]
                gamma=fixed_aux,   # [å›ºå®š]
                device=device,
                verbose=False)

    # =================================================================
    # 3. åŠ¨æ€æ³¨å…¥å‚æ•°
    # =================================================================
    
    # A. Scale
    for module in model.modules():
        if hasattr(module, 'min_scale_val'):
            module.min_scale_val = suggest_min_scale
            module.max_scale_val = 0.20 # å›ºå®šä¸Šé™

    # B. Loss æƒé‡
    model.router_weight = fixed_router_w
    model.beta = fixed_beta          # [å›ºå®š]
    model.alpha_balance = suggest_alpha # [æœç´¢]
    model.ortho_weight = fixed_ortho # [å›ºå®š]
    
    # C. Threshold
    if args.n_shot == 1:
        model.fidelity_threshold_1shot = fixed_fid_thresh
    else:
        model.fidelity_threshold_5shot = fixed_fid_thresh

    # D. LR æ³¨å…¥
    # 1. Head (å€’æ•°ç¬¬1ç»„)
    if len(model.optimizer.param_groups) >= 1:
        model.optimizer.param_groups[-1]['lr'] = suggest_lr_head
        
    # 2. Adapter Scale (å€’æ•°ç¬¬2ç»„)
    if len(model.optimizer.param_groups) >= 2:
        model.optimizer.param_groups[-2]['lr'] = suggest_lr_adapter
        
    # 3. Adapter Weights (å€’æ•°ç¬¬3ç»„)
    if len(model.optimizer.param_groups) >= 3:
        model.optimizer.param_groups[-3]['lr'] = suggest_lr_adapter

    # =================================================================
    # 4. CSV Logging (ç²¾ç®€ç‰ˆ)
    # =================================================================
    log_filename = f"search_log_{args.dataset_name}_{args.n_shot}shot_smart.csv"
    
    if not os.path.exists(log_filename):
        with open(log_filename, mode='w', newline='') as f:
            writer = csv.writer(f)
            # åªè®°å½•å˜åŒ–çš„å‚æ•°ï¼Œå›ºå®šçš„å°±ä¸è®°äº†
            header = ['Trial_ID', 'mAP', 'Min_Scale', 'Alpha', 'LR_Adap', 'LR_Head']
            writer.writerow(header)

    # =================================================================
    # 5. è®­ç»ƒå¾ªç¯
    # =================================================================
    train_loader = get_dataloader(args.dataset_name, 'train', 
                                  DEFAULT_CONFIG['n_way'], args.n_shot, 
                                  5, True, 200, DEFAULT_CONFIG['num_workers'], 224)
    val_loader = get_dataloader(args.dataset_name, 'val', 
                                DEFAULT_CONFIG['n_way'], args.n_shot, 
                                5, False, 100, DEFAULT_CONFIG['num_workers'], 224)

    best_mAP = 0.0
    
    print(f"\nğŸš€ Trial {trial.number}: Scale={suggest_min_scale:.2f}, Alpha={suggest_alpha}, "
          f"LR_Adp={suggest_lr_adapter:.1e}, LR_Head={suggest_lr_head:.1e}")

    for epoch in range(DEFAULT_CONFIG['max_epoch']):
        try:
            model.train_loop(train_loader)
            result = model.test_loop(val_loader)
            mAP = result['mAP']
        except Exception as e:
            print(f"Error in trial {trial.number}: {e}")
            return 0.0 

        if mAP > best_mAP:
            best_mAP = mAP
        
        trial.report(mAP, epoch)
        if trial.should_prune():
            raise optuna.TrialPruned()

    # å†™å…¥ç»“æœ
    with open(log_filename, mode='a', newline='') as f:
        writer = csv.writer(f)
        row = [
            trial.number,
            f"{best_mAP:.4f}",
            f"{suggest_min_scale:.4f}",
            f"{suggest_alpha:.1f}",
            f"{suggest_lr_adapter:.6f}",
            f"{suggest_lr_head:.6f}"
        ]
        writer.writerow(row)
        print(f"ğŸ’¾ [Saved] Trial {trial.number} (mAP: {best_mAP:.2f})")

    return best_mAP

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset_name', type=str, default='COCO', help='Name of the dataset')
    parser.add_argument('--n_shot', type=int, default=5, choices=[1, 5], help='Number of shots')
    parser.add_argument('--n_trials', type=int, default=30, help='Number of trials')
    args = parser.parse_args()

    # ä½¿ç”¨æ–°çš„æ•°æ®åº“åï¼Œé¿å…æ··æ·†
    db_name = f"bcr_search_{args.dataset_name}_{args.n_shot}shot_smart"
    storage_name = f"sqlite:///{db_name}.db"
    
    print(f"ğŸš€ Starting Smart Search: Dataset={args.dataset_name}, Shot={args.n_shot}")
    
    study = optuna.create_study(
        study_name=db_name,
        direction="maximize",
        storage=storage_name,
        load_if_exists=True,
        sampler=optuna.samplers.TPESampler()
    )
    
    study.optimize(lambda trial: objective(trial, args), n_trials=args.n_trials)