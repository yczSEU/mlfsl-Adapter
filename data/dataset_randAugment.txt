import numpy as np
import os
from torch.utils.data import Dataset
import torch
from PIL import Image, ImageOps, ImageEnhance
from scipy.sparse import load_npz
from torchvision import transforms
import random

current_path = os.path.dirname(__file__)

path_to_images_dict = {
    'CUB': os.path.join(current_path, '../../data/MLL/CUB/CUB_200_2011/images'),
    'COCO': '/root/autodl-tmp/data/coco',
    'NUSWIDE': os.path.join(current_path, '../../data/MLL/NUSWIDE/Flickr'),
    'VG': '/autodl-fs/data/VG/VG_merged',
}

IDX_FOLDER = 'idx' 

# =========================================================
# 1. RandAugment (极速版：纯 PIL 操作，无 Tensor 转换)
# =========================================================
class RandAugment(object):
    def __init__(self, num_ops=2, magnitude=9):
        self.num_ops = num_ops
        self.magnitude = magnitude
        self.operations = [
            self.autocontrast,
            self.equalize,
            self.flip,
            self.rotate,
            self.color,
            self.posterize,
            self.contrast,
            self.brightness,
            self.sharpness,
        ]

    def __call__(self, img):
        # 输入 img 是 PIL Image，输出也是 PIL Image
        # 没有任何 Tensor 转换开销
        ops = random.sample(self.operations, self.num_ops)
        for op in ops:
            img = op(img)
        return img

    def autocontrast(self, img):
        return ImageOps.autocontrast(img)

    def equalize(self, img):
        return ImageOps.equalize(img)

    def flip(self, img):
        if random.random() > 0.5:
            return img.transpose(Image.FLIP_LEFT_RIGHT)
        else:
            return img.transpose(Image.FLIP_TOP_BOTTOM)

    def rotate(self, img):
        angle = random.randint(-self.magnitude, self.magnitude)
        return img.rotate(angle)

    def color(self, img):
        factor = random.uniform(1 - self.magnitude / 10, 1 + self.magnitude / 10)
        return ImageEnhance.Color(img).enhance(factor)

    def posterize(self, img):
        bits = random.randint(4, 8)
        return ImageOps.posterize(img, bits)

    def contrast(self, img):
        factor = random.uniform(1 - self.magnitude / 10, 1 + self.magnitude / 10)
        return ImageEnhance.Contrast(img).enhance(factor)

    def brightness(self, img):
        factor = random.uniform(1 - self.magnitude / 10, 1 + self.magnitude / 10)
        return ImageEnhance.Brightness(img).enhance(factor)

    def sharpness(self, img):
        factor = random.uniform(1 - self.magnitude / 10, 1 + self.magnitude / 10)
        return ImageEnhance.Sharpness(img).enhance(factor)


# =========================================================
# 2. Dataset 和 Sampler (保持不变)
# =========================================================

class MLLDataset(Dataset):
    def __init__(self, dataset_name, phase='train', transform=True, image_size=84):
        self.dataset_name = dataset_name
        file_prefix = 'COCO2014' if dataset_name == 'COCO' else dataset_name
        
        self.images = np.load(os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_{phase}_images.npy'), allow_pickle=True)
        self.labels = load_npz(
            os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_{phase}_labels.npz')).toarray()
            
        self.image_transform = get_transform(transform=transform, image_size=image_size) 
        self.max_idx = self.images.shape[0]
        self.image_size = image_size

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        if index < self.labels.shape[0]:
            image = Image.open(os.path.join(path_to_images_dict[self.dataset_name], self.images[index])).convert('RGB')
            image = self.image_transform(image)
            labels = torch.Tensor(self.labels[index])
            sample = {'image': image, 'labels': labels, 'idx': index}
        else:
            sample = {}
            sample['image'] = torch.zeros([3, self.image_size, self.image_size])
            sample['labels'] = torch.zeros([self.labels.shape[1]])
            sample['labels'][index - self.max_idx] = 1
            sample['idx'] = index
        return sample


class EpisodeSampler:
    def __init__(self, dataset_name, n_way, n_shot, max_idx,
                 n_query=16, phase='val', iter=100):
        self.dataset_name = dataset_name
        self.n_way = n_way
        self.n_shot = n_shot
        self.n_query = n_query
        
        file_prefix = 'COCO2014' if dataset_name == 'COCO' else dataset_name
        
        self.labels = load_npz(
            os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_{phase}_labels.npz')).toarray()
        assert self.labels.shape[1] >= self.n_way 
        
        self.images = np.load(os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_{phase}_images.npy'),allow_pickle=True)
        
        self.label_to_idx_dict = \
            np.load(os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_' + phase + '_label_to_idx_dict.npy'),
                    allow_pickle=True)[0]
        self.iter = iter
        self.max_idx = max_idx
        self.phase = phase

    def __len__(self):
        return self.iter

    def __iter__(self):
        for _ in range(self.iter):
            sampled_class = np.random.choice(np.arange(self.labels.shape[1]), size=self.n_way, replace=False)
            support_idx = []
            query_idx = []
            for c in sampled_class:
                idx = np.random.choice(self.label_to_idx_dict[c],
                                       size=np.minimum(self.n_shot + self.n_query, len(self.label_to_idx_dict[c])),
                                       replace=False)
                support_idx.extend(idx[:self.n_shot])
                query_idx.extend(idx[self.n_shot:])

            last_set = list(set(query_idx) - set(support_idx))
            
            if self.phase == 'train':
                 query_idx = np.random.choice(list(last_set), size= 4 * self.n_query, replace=False)
            else:
                 query_idx = np.random.choice(list(last_set), size= self.n_query, replace=False)
            
            class_idx = self.max_idx + sampled_class
            if self.n_query == 0:
                all_idx = np.concatenate([support_idx, class_idx])
            else:
                all_idx = np.concatenate([support_idx, query_idx, class_idx])
            
            yield all_idx


# =========================================================
# 3. 核心修改：顺序调整 (PIL -> Augment -> ToTensor)
# =========================================================

def get_transform(transform, image_size, n_shot=5):
    mean = [0.48145466, 0.4578275, 0.40821073]
    std = [0.26862954, 0.26130258, 0.27577711]

    if transform:
        # === 【训练模式】 ===
        ops = [
            # 1. PIL 操作
            transforms.RandomResizedCrop((image_size, image_size), scale=(0.3, 1.0)),
            transforms.RandomHorizontalFlip(),
        ]
        
        # 2. 强增强 (直接处理 PIL，无需转换)
        if n_shot > 1:
            ops.append(RandAugment(num_ops=2, magnitude=9))
            
        # 3. 最后才转 Tensor 和 归一化 (只做一次转换，速度起飞)
        ops.append(transforms.ToTensor())
        ops.append(transforms.Normalize(mean=mean, std=std))
        
        return transforms.Compose(ops)
    else:
        return transforms.Compose([
            transforms.Resize((int(image_size * 1.15), int(image_size * 1.15))),
            transforms.CenterCrop((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])


def generate_MetaDataset(dataset_name, n_way, n_shot, image_size=224,
                         n_query=16, phase='val', transform=False):
    # 路径修正
    file_prefix = 'COCO2014' if dataset_name == 'COCO' else dataset_name
    
    images = np.load(os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_{phase}_images.npy'),allow_pickle=True)
    labels = load_npz(os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_{phase}_labels.npz')).toarray()
    
    assert labels.shape[1] >= n_way 
    
    sampled_class = np.random.choice(np.arange(labels.shape[1]), size=n_way, replace=False)
    support_idx = []
    query_idx = []
    
    label_to_idx_dict = \
        np.load(os.path.join(current_path, IDX_FOLDER, f'{file_prefix}_' + phase + '_label_to_idx_dict.npy'),
                allow_pickle=True)[0]
                
    for c in sampled_class:
        idx = np.random.choice(label_to_idx_dict[c], size=np.minimum(n_shot + n_query, len(label_to_idx_dict[c])),
                               replace=False)
        support_idx.extend(idx[:n_shot])
        query_idx.extend(idx[n_shot:])
        
    support_idx = np.array(list(set(support_idx)))
    query_idx = np.array(list(set(query_idx) - set(support_idx)))
    
    # 传入 n_shot
    train_transform = get_transform(transform=True, image_size=image_size, n_shot=n_shot)
    test_transform = get_transform(transform=False, image_size=image_size, n_shot=n_shot)
    
    x_support = torch.zeros([len(support_idx), 3, image_size, image_size])
    for i, s in enumerate(support_idx):
        image = Image.open(os.path.join(path_to_images_dict[dataset_name], images[s])).convert('RGB')
        x_support[i] = train_transform(image) # 极速版增强
        
    x_query = torch.zeros([len(query_idx), 3, image_size, image_size])
    for i, q in enumerate(query_idx):
        image = Image.open(os.path.join(path_to_images_dict[dataset_name], images[q])).convert('RGB')
        x_query[i] = test_transform(image)
        
    y_support = torch.from_numpy(labels[support_idx][:, sampled_class])
    y_query = torch.from_numpy(labels[query_idx][:, sampled_class])
    
    test_loader = (x_support, y_support, x_query, y_query)
    return test_loader